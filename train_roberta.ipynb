{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-05T10:23:45.947451Z","iopub.execute_input":"2021-12-05T10:23:45.948003Z","iopub.status.idle":"2021-12-05T10:23:46.003776Z","shell.execute_reply.started":"2021-12-05T10:23:45.947849Z","shell.execute_reply":"2021-12-05T10:23:46.002680Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport multiprocessing\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport emoji\nimport re\nfrom tqdm.notebook import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup","metadata":{"execution":{"iopub.status.busy":"2021-12-05T10:23:46.006637Z","iopub.execute_input":"2021-12-05T10:23:46.007145Z","iopub.status.idle":"2021-12-05T10:23:54.825915Z","shell.execute_reply.started":"2021-12-05T10:23:46.007059Z","shell.execute_reply":"2021-12-05T10:23:54.824929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model_name = \"sentence-transformers/bert-base-nli-mean-tokens\"\nmodel_name = \"cardiffnlp/twitter-roberta-base\"\n# model_name = \"roberta-base\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2021-12-05T10:23:54.827585Z","iopub.execute_input":"2021-12-05T10:23:54.827860Z","iopub.status.idle":"2021-12-05T10:24:02.300833Z","shell.execute_reply.started":"2021-12-05T10:23:54.827819Z","shell.execute_reply":"2021-12-05T10:24:02.299819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"annotated = pd.read_csv('../input/annotated-clean/annotated_clean.csv')\nannotated.head(5)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2021-12-05T10:24:02.304280Z","iopub.execute_input":"2021-12-05T10:24:02.304938Z","iopub.status.idle":"2021-12-05T10:24:02.381760Z","shell.execute_reply.started":"2021-12-05T10:24:02.304747Z","shell.execute_reply":"2021-12-05T10:24:02.380727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labeled_tweets = annotated.rename({'tweet_text': 'text'}, axis=1)\nlabeled_tweets['label'] = labeled_tweets['label']-1\n\ntrain_size = 0.8\ntrain_data=labeled_tweets.sample(frac=train_size,random_state=200)\ntest_data=labeled_tweets.drop(train_data.index).reset_index(drop=True)\ntrain_data = train_data.reset_index(drop=True)\n\nprint(\"FULL Dataset: {}\".format(labeled_tweets.shape))\nprint(\"TRAIN Dataset: {}\".format(train_data.shape))\nprint(\"TEST Dataset: {}\".format(test_data.shape))","metadata":{"execution":{"iopub.status.busy":"2021-12-05T10:24:02.385585Z","iopub.execute_input":"2021-12-05T10:24:02.385835Z","iopub.status.idle":"2021-12-05T10:24:02.411760Z","shell.execute_reply.started":"2021-12-05T10:24:02.385805Z","shell.execute_reply":"2021-12-05T10:24:02.410067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def encode_sentences(sentences):\n    encoded = tokenizer(sentences, padding=True, return_attention_mask=True, return_tensors='pt')\n    return encoded\n\ndef collate_batch(batch):\n    sentences, targets = list(zip(*batch))\n    encoded = encode_sentences(list(sentences))\n    targets = torch.tensor(targets)\n    return encoded, targets\n\nclass TweetDataset(torch.utils.data.Dataset):    \n    def __init__(self, df):\n        self.df = df.text.to_list()\n        self.targets = df.label.to_list()\n     \n    def __getitem__(self, idx):\n        sentence = self.df[idx]\n        target = self.targets[idx]\n        return sentence, target\n     \n    def __len__(self):\n        return len(self.df)","metadata":{"execution":{"iopub.status.busy":"2021-12-05T10:24:02.413462Z","iopub.execute_input":"2021-12-05T10:24:02.413772Z","iopub.status.idle":"2021-12-05T10:24:02.423790Z","shell.execute_reply.started":"2021-12-05T10:24:02.413733Z","shell.execute_reply":"2021-12-05T10:24:02.422598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport multiprocessing\ntrain_dataset = TweetDataset(train_data)\ntrain_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=16, collate_fn=collate_batch, num_workers=(multiprocessing.cpu_count() - 1), pin_memory=True)\n\ntest_dataset = TweetDataset(test_data)\ntest_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=16, collate_fn=collate_batch, num_workers=(multiprocessing.cpu_count() - 1), pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-05T10:24:02.425427Z","iopub.execute_input":"2021-12-05T10:24:02.426527Z","iopub.status.idle":"2021-12-05T10:24:02.437177Z","shell.execute_reply.started":"2021-12-05T10:24:02.426476Z","shell.execute_reply":"2021-12-05T10:24:02.436083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self, model_name, num_classes):\n        super(Model, self).__init__()\n        self.encoder = AutoModel.from_pretrained(model_name)\n        hidden_size = self.encoder.config.hidden_size\n        self.classify = nn.Sequential(\n            nn.LayerNorm(hidden_size),\n            nn.Dropout(0.3),\n            nn.Linear(hidden_size, num_classes)\n        )\n        \n    def mean_pooling(self, outputs, attention_mask):\n        token_embeddings = outputs[0] #First element of model_output contains all token embeddings\n        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n    \n    def forward(self, inputs):\n        outputs = self.encoder(**inputs)\n        return self.classify(outputs[1])","metadata":{"execution":{"iopub.status.busy":"2021-12-05T10:24:02.440520Z","iopub.execute_input":"2021-12-05T10:24:02.441205Z","iopub.status.idle":"2021-12-05T10:24:02.451437Z","shell.execute_reply.started":"2021-12-05T10:24:02.441158Z","shell.execute_reply":"2021-12-05T10:24:02.450454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Model(model_name, 3)\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2021-12-05T10:24:02.453452Z","iopub.execute_input":"2021-12-05T10:24:02.453788Z","iopub.status.idle":"2021-12-05T10:24:28.692566Z","shell.execute_reply.started":"2021-12-05T10:24:02.453748Z","shell.execute_reply":"2021-12-05T10:24:28.691566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 5\nloss_fn = nn.CrossEntropyLoss().to(device)\noptimizer = optim.AdamW(model.parameters(), betas = (0.99, 0.98), lr=2e-5)\ntotal_steps = len(train_dataloader) * EPOCHS\nscheduler = get_linear_schedule_with_warmup(\n  optimizer,\n  num_warmup_steps=0,\n  num_training_steps=total_steps\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-05T10:24:28.696395Z","iopub.execute_input":"2021-12-05T10:24:28.696719Z","iopub.status.idle":"2021-12-05T10:24:28.705388Z","shell.execute_reply.started":"2021-12-05T10:24:28.696674Z","shell.execute_reply":"2021-12-05T10:24:28.703937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(model, dataloader, loss_fn, optimizer, scheduler):\n    model = model.train()\n    losses = []\n    correct_predictions = 0\n    for sentences, targets in tqdm(dataloader):\n        input_ids = sentences[\"input_ids\"].to(device)\n        attention_mask = sentences[\"attention_mask\"].to(device)\n        targets = targets.to(device)\n        \n        optimizer.zero_grad()        \n        outputs = model(dict(\n            input_ids=input_ids,\n            attention_mask=attention_mask\n        ))\n        \n        train_loss = loss_fn(outputs, targets)\n        train_loss.backward()\n        losses.append(train_loss.item())\n        \n        _, preds = torch.max(outputs, dim=1)\n        correct_predictions += torch.sum(preds == targets)\n        \n        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        optimizer.step()\n        scheduler.step()\n    return correct_predictions.double() / len(dataloader.dataset), np.mean(losses)","metadata":{"execution":{"iopub.status.busy":"2021-12-05T10:24:28.707949Z","iopub.execute_input":"2021-12-05T10:24:28.709060Z","iopub.status.idle":"2021-12-05T10:24:28.722351Z","shell.execute_reply.started":"2021-12-05T10:24:28.708764Z","shell.execute_reply":"2021-12-05T10:24:28.721219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def validate(model, dataloader, loss_fn):\n    model = model.eval()\n    losses = []\n    correct_predictions = 0\n    with torch.no_grad():\n        for sentences, targets in tqdm(dataloader):\n            input_ids = sentences[\"input_ids\"].to(device)\n            attention_mask = sentences[\"attention_mask\"].to(device)\n            targets = targets.to(device)\n            \n            outputs = model(dict(\n                input_ids=input_ids,\n                attention_mask=attention_mask\n            ))\n            \n            val_loss = loss_fn(outputs, targets)\n            losses.append(val_loss.item())\n            \n            _, preds = torch.max(outputs, dim=1)\n            correct_predictions += torch.sum(preds == targets)\n            \n    return correct_predictions.double() / len(dataloader.dataset), np.mean(losses)","metadata":{"execution":{"iopub.status.busy":"2021-12-05T10:24:28.724079Z","iopub.execute_input":"2021-12-05T10:24:28.724480Z","iopub.status.idle":"2021-12-05T10:24:28.737342Z","shell.execute_reply.started":"2021-12-05T10:24:28.724437Z","shell.execute_reply":"2021-12-05T10:24:28.736389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(EPOCHS):\n    print(f\"Epoch: {epoch + 1} / {EPOCHS}\")\n    \n    train_accuracy, train_loss = train(model, train_dataloader, loss_fn, optimizer, scheduler)\n    val_accuracy, val_loss = validate(model, test_dataloader, loss_fn)\n    \n    print(f\"Training Loss: {train_loss} | Training Accuracy: {train_accuracy}\")\n    print(f\"Validation Loss: {val_loss} | Validation Accuracy: {val_accuracy}\")  ","metadata":{"execution":{"iopub.status.busy":"2021-12-05T10:24:28.741141Z","iopub.execute_input":"2021-12-05T10:24:28.741399Z","iopub.status.idle":"2021-12-05T10:29:45.506965Z","shell.execute_reply.started":"2021-12-05T10:24:28.741360Z","shell.execute_reply":"2021-12-05T10:29:45.505774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_tweet = pd.read_csv(\"../input/all-tweets-cleaned/all_tweets_cleaned.csv\")\nall_tweet['label'] = 0\nall_tweet.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-12-05T11:29:19.139164Z","iopub.execute_input":"2021-12-05T11:29:19.140051Z","iopub.status.idle":"2021-12-05T11:29:20.298906Z","shell.execute_reply.started":"2021-12-05T11:29:19.140017Z","shell.execute_reply":"2021-12-05T11:29:20.297768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef predict(model, dataloader):\n    prediction_list = []\n    model = model.eval()\n    with torch.no_grad():\n        for sentences, targets in tqdm(dataloader):\n            input_ids = sentences[\"input_ids\"].to(device)\n            attention_mask = sentences[\"attention_mask\"].to(device)\n            targets = targets.to(device)\n            \n            outputs = model(dict(\n                input_ids=input_ids,\n                attention_mask=attention_mask\n            ))\n            \n            predictions = np.argmax(outputs.cpu(), axis=1)\n            prediction_list = prediction_list + predictions.tolist()\n            \n    return prediction_list","metadata":{"execution":{"iopub.status.busy":"2021-12-05T11:01:41.119493Z","iopub.execute_input":"2021-12-05T11:01:41.119794Z","iopub.status.idle":"2021-12-05T11:01:41.127209Z","shell.execute_reply.started":"2021-12-05T11:01:41.119764Z","shell.execute_reply":"2021-12-05T11:01:41.125983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = TweetDataset(all_tweet)\ntest_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=64, collate_fn=collate_batch, num_workers=(multiprocessing.cpu_count() - 1), pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-05T11:29:32.924199Z","iopub.execute_input":"2021-12-05T11:29:32.924995Z","iopub.status.idle":"2021-12-05T11:29:32.944949Z","shell.execute_reply.started":"2021-12-05T11:29:32.924876Z","shell.execute_reply":"2021-12-05T11:29:32.943934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction_list = predict(model, test_dataloader)","metadata":{"execution":{"iopub.status.busy":"2021-12-05T11:29:37.797736Z","iopub.execute_input":"2021-12-05T11:29:37.798245Z","iopub.status.idle":"2021-12-05T11:35:16.327960Z","shell.execute_reply.started":"2021-12-05T11:29:37.798211Z","shell.execute_reply":"2021-12-05T11:35:16.326918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_tweet.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-12-05T11:35:18.654648Z","iopub.execute_input":"2021-12-05T11:35:18.655383Z","iopub.status.idle":"2021-12-05T11:35:18.669976Z","shell.execute_reply.started":"2021-12-05T11:35:18.655347Z","shell.execute_reply":"2021-12-05T11:35:18.668999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_tweet['label'] = prediction_list","metadata":{"execution":{"iopub.status.busy":"2021-12-05T11:35:32.757784Z","iopub.execute_input":"2021-12-05T11:35:32.758148Z","iopub.status.idle":"2021-12-05T11:35:32.851512Z","shell.execute_reply.started":"2021-12-05T11:35:32.758103Z","shell.execute_reply":"2021-12-05T11:35:32.850391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_tweet.head(5)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-05T11:35:34.479984Z","iopub.execute_input":"2021-12-05T11:35:34.480565Z","iopub.status.idle":"2021-12-05T11:35:34.495035Z","shell.execute_reply.started":"2021-12-05T11:35:34.480530Z","shell.execute_reply":"2021-12-05T11:35:34.493959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_tweet['label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-12-05T11:35:40.025026Z","iopub.execute_input":"2021-12-05T11:35:40.025888Z","iopub.status.idle":"2021-12-05T11:35:40.037109Z","shell.execute_reply.started":"2021-12-05T11:35:40.025841Z","shell.execute_reply":"2021-12-05T11:35:40.035863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_tweet.to_csv(\"all_tweet_labeled.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-12-05T11:36:20.655524Z","iopub.execute_input":"2021-12-05T11:36:20.655919Z","iopub.status.idle":"2021-12-05T11:36:23.051428Z","shell.execute_reply.started":"2021-12-05T11:36:20.655860Z","shell.execute_reply":"2021-12-05T11:36:23.050115Z"},"trusted":true},"execution_count":null,"outputs":[]}]}